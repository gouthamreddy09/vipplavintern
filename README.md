ğŸ¨ Stable Diffusion Fine-tuning with Flickr30k Dataset

ğŸš€ Overview

This project demonstrates fine-tuning Stable Diffusion v1.4 on the Flickr30k dataset using Google Colab. The pipeline is designed for custom image generation, multilingual prompt support (Telugu included), and efficient training in a constrained GPU environment.

Key highlights:
	â€¢	âœ… Fine-tuned Stable Diffusion on 30,000+ images with captions
	â€¢	âœ… Added Telugu prompt support (via Google Translate)
	â€¢	âœ… Optimized training for Google Colab GPUs (6â€“8GB VRAM)
	â€¢	âœ… Reusable modular pipeline with Hugging Face Diffusers

â¸»

ğŸ“¦ Prerequisites & Setup

Install Dependencies

pip install datasets transformers sentencepiece diffusers torch accelerate huggingface_hub googletrans

Authenticate with Hugging Face

from huggingface_hub import login
login()  # Requires your Hugging Face token


â¸»

ğŸ“‚ Dataset Preparation

Dataset: Flickr30k
	â€¢	Images: 31,783
	â€¢	Captions: 158,915 (5 per image)
	â€¢	Size: ~1.2 GB

Steps:
	1.	Clone and unzip Flickr30k dataset
	2.	Parse captions into separate rows
	3.	Create Hugging Face dataset for efficient loading

!git clone https://huggingface.co/datasets/nlphuji/flickr30k
!unzip flickr30k/flickr30k-images.zip -d flickr30k/images


â¸»

ğŸ§© Model Architecture
	â€¢	Base Model: CompVis/stable-diffusion-v1-4
	â€¢	Components:
	â€¢	VAE â†’ encodes & decodes latent space
	â€¢	CLIP Text Encoder â†’ converts prompts to embeddings
	â€¢	UNet â†’ denoising network (fine-tuned)
	â€¢	Scheduler â†’ controls noise schedule

â¸»

ğŸ¯ Fine-tuning

Training Configuration:
	â€¢	Learning Rate: 1e-5
	â€¢	Batch Size: 4
	â€¢	Precision: fp16 (mixed precision)
	â€¢	Optimizer: AdamW
	â€¢	Epochs: 3

Pipeline:
	1.	Resize images to 512Ã—512
	2.	Normalize to [-1, 1]
	3.	Encode latents with VAE
	4.	Train UNet with text-image pairs

â¸»

ğŸ–¼ï¸ Testing & Inference

Baseline (Before Fine-tuning)

from diffusers import StableDiffusionPipeline

pipe = StableDiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4").to("cuda")
prompt = "royal enfield gt650"
image = pipe(prompt).images[0]
image.show()

Fine-tuned Model (After Training)

fine_tuned_pipe = StableDiffusionPipeline(
    vae=vae, text_encoder=text_encoder, tokenizer=tokenizer, unet=unet, scheduler=noise_scheduler
).to("cuda")

prompt = "A photo of a person riding a bicycle"
image = fine_tuned_pipe(prompt).images[0]
image.show()


â¸»

ğŸŒ Multilingual Support (Telugu Example)

from googletrans import Translator
translator = Translator()

telugu_prompt = "à°•à±à°°à°¿à°•à±†à°Ÿà± à°†à°¡à±à°¤à±à°¨à±à°¨ à°¬à°¾à°²à±à°¡à±"  # "A boy playing cricket"
english_prompt = translator.translate(telugu_prompt, src='te', dest='en').text

image = fine_tuned_pipe(english_prompt).images[0]
image.show()


â¸»

ğŸ“Š Performance

Component	GPU Memory	Time per step
VAE Encoding	~2GB	~0.1s/image
Text Encoding	~1GB	~0.01s/prompt
UNet Forward	~4GB	~0.5s/step
Training (epoch)	~8GB	~30 min


â¸»

ğŸ Troubleshooting
	â€¢	CUDA OOM â†’ Reduce batch size, enable fp16, use gradient accumulation
	â€¢	Dataset issues â†’ Check paths & formats (os.path.exists)
	â€¢	Training instability â†’ Use gradient clipping & lower LR
	â€¢	Slow data loading â†’ Use Hugging Face datasets with transforms

â¸»

ğŸŒŸ Future Enhancements
	â€¢	LoRA fine-tuning (efficient training)
	â€¢	DreamBooth for personal object/face training
	â€¢	Advanced schedulers (DDIM, DPM-Solver++)
	â€¢	Gradio/Streamlit web interface
	â€¢	Automated evaluation with FID & CLIP scores

â¸»

ğŸ“– License

This project is released under the MIT License.
